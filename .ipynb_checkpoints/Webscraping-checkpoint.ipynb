{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf7dc368",
   "metadata": {},
   "source": [
    "# Webscraping\n",
    "\n",
    "***Scraping the Internet Programmatically***\n",
    "\n",
    "# Getting Started\n",
    "\n",
    "The libraries needed for reading in HTML from sites:\n",
    "\n",
    "- **requests:** Make GET requests to the internet to go out and get the HTML for a site\n",
    "\n",
    "- **bs4:** Parse through a set of HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cba857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3f6f7",
   "metadata": {},
   "source": [
    "## Loading In a Webpage\n",
    "\n",
    "While the get function has several extra parameters, the main two are the url and params.\n",
    "\n",
    "`requests.get(url, params=None)`\n",
    "\n",
    "- **url:** The link to retrieve the HTML from\n",
    "\n",
    "- **params:** A dictionary of parameters to add as a *query string* on top of the link. If it's None, nothing is added to the url\n",
    "\n",
    "    - *query string:* Extra piece of the link to specify further what you want from site (addition looks like **\"?key1=value1&key2=value2\"**)\n",
    "\n",
    "You can then see the HTML from the response by getting **.text** from the request object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "564d3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>My html page</title>\n",
      "</head>\n",
      "<body>\n",
      "\n",
      "    <p>\n",
      "        Today is a beautiful day. We go swimming and fishing.\n",
      "    </p>\n",
      "    \n",
      "    <p>\n",
      "         Hello there. How are you?\n",
      "    </p>\n",
      "    \n",
      "</body>\n",
      "</html>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"http://webcode.me\"\n",
    "my_request = requests.get(url)\n",
    "print(my_request.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7651852",
   "metadata": {},
   "source": [
    "## Getting Your Soup\n",
    "\n",
    "The bs4 library takes this long HTML string and turns it into a BeautifulSoup object that has several functions that make navigating the HTML to the data you want easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238ca335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "<title>My html page</title>\n",
      "</head>\n",
      "<body>\n",
      "<p>\n",
      "        Today is a beautiful day. We go swimming and fishing.\n",
      "    </p>\n",
      "<p>\n",
      "         Hello there. How are you?\n",
      "    </p>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(my_request.text, 'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b2cece",
   "metadata": {},
   "source": [
    "# Basic Navigation\n",
    "\n",
    "Your *soup* object is associated with all the HTML, but if you know the outermost tag that you want to navigate to. Let's try to get the *title* tag for this HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dcc84e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>My html page</title>\n"
     ]
    }
   ],
   "source": [
    "title = soup.title\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b22ee0",
   "metadata": {},
   "source": [
    "Nice! If you want to get the text that is contained within a singular element, you can access this by getting the **.text** of a BeautifulSoup object that you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79c8c4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My html page\n"
     ]
    }
   ],
   "source": [
    "print(title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e645c12",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "How can we get the text from the first p tag that we see in the HTML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a7ac4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0734b059",
   "metadata": {},
   "source": [
    "# Searching by Tags\n",
    "\n",
    "While the method of getting each element is effective, with big webpages, there would be a ton of steps you would have to take to get to the information you want. Luckily, the bs4 library has some methods that let us get to the tags we want faster:\n",
    "\n",
    "`BeautifulSoup.find_all(name, attrs, recursive, string, limit)`\n",
    "\n",
    "This method gets all the tags that fit the arguments you give it:\n",
    "\n",
    "- **name:** The tag type (things like *div, p, button*)\n",
    "\n",
    "- **attrs:** Tags often come with inner information (attributes). We can use this as a way of filtering our search. We pass a dictionary of {attribute_name: attribute_value} to attrs to filter our search\n",
    "\n",
    "    - example of attributes: <div **class=\"my-special-div\"**>\n",
    "    \n",
    "- **recursive:** This parameter is by default true. If true, the function searches in you current BeautifulSoup object as well as any nested tags within\n",
    "\n",
    "- **limit:** If there's a maximum number of elements that you want, you can specify this with the limit parameter\n",
    "\n",
    "- **string:** Filters tag search to those that have a given string as a the text inside.\n",
    "\n",
    "`BeautifulSoup.find(name, attrs, recursive, string)`\n",
    "\n",
    "This method does basically the same as *find_all*, but just returns *None* if no tag is found.\n",
    "\n",
    "Let's try and get information from the premier league soccer standings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60648b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This HTML has 991324 characters!\n"
     ]
    }
   ],
   "source": [
    "premier_league_html_string = requests.get(\"https://www.premierleague.com/tables\").text\n",
    "soup2 = BeautifulSoup(premier_league_html_string, \"html.parser\")\n",
    "print(\"This HTML has \" + str(len(premier_league_html_string)) + \" characters!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ff8fc",
   "metadata": {},
   "source": [
    "That's a lot of HTML to navigate. Let's try using find_all to get the tags that have the names of the teams instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abb67a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<td class=\"team\" scope=\"row\">\n",
      "<a href=\"/clubs/11/Manchester-City/overview\">\n",
      "<span class=\"badge badge-image-container\" data-size=\"25\" data-widget=\"club-badge-image\">\n",
      "<img class=\"badge-image badge-image--25\" src=\"https://resources.premierleague.com/premierleague/badges/25/t43.png\" srcset=\"https://resources.premierleague.com/premierleague/badges/25/t43@x2.png 2x\">\n",
      "</img></span>\n",
      "<span class=\"long\">Manchester City</span>\n",
      "<span class=\"short\">MCI</span>\n",
      "</a>\n",
      "</td>\n"
     ]
    }
   ],
   "source": [
    "all_teams = soup2.find_all(\"td\", {\"class\": \"team\"})\n",
    "first_place = all_teams[0]\n",
    "print(first_place)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3251cd3c",
   "metadata": {},
   "source": [
    "That's pretty close! From here we can probably get the name of the team from this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e9d80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"long\">Manchester City</span>\n",
      "Manchester City\n"
     ]
    }
   ],
   "source": [
    "first_place_name = first_place.find(\"span\", {\"class\": \"long\"})\n",
    "print(first_place_name)\n",
    "print(first_place_name.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82932ead",
   "metadata": {},
   "source": [
    "## Your Turn\n",
    "\n",
    "Write a little code to go through all teams and print out the standings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c1136",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2d031f4",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "And that's it! You now know the basic of scraping websites and you can apply this mentality of following the tags to any website to pull information out of it programmatically. Enjoy scraping!\n",
    "\n",
    "For more information on the bs4 libray: https://beautiful-soup-4.readthedocs.io/en/latest/#id12\n",
    "\n",
    "---\n",
    "\n",
    "This notebook was created by Jonathan Keane for MSOE's GDSC webscraping workshop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
